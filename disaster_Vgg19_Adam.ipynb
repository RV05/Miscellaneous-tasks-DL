{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "disaster_Vgg19_Adam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RV05/Miscellaneous-tasks-DL/blob/main/disaster_Vgg19_Adam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01lAEMug9uHN",
        "outputId": "adf2684c-6528-4256-da89-b486f4a7df2a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsYuPMHtVa8p",
        "outputId": "1bf1bc4d-6c43-4fd1-abca-c5a877eb1f12"
      },
      "source": [
        "cd /content/drive/MyDrive/deep learning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/deep learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT5oQ9GQegzo"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "# import the necessary packages\n",
        "import config\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "# ap = argparse.ArgumentParser()\n",
        "# ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
        "# \thelp=\"path to output loss/accuracy plot\")\n",
        "# args = vars(ap.parse_args())\n",
        "# # determine the total number of image paths in training, validation,\n",
        "# # and testing directories\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2W2oRSbfwYi"
      },
      "source": [
        "totalTrain = len(list(paths.list_images(config.TRAIN_PATH)))\n",
        "totalVal = len(list(paths.list_images(config.VAL_PATH)))\n",
        "totalTest = len(list(paths.list_images(config.TEST_PATH)))\n",
        "trainAug = ImageDataGenerator(\n",
        "\t# rotation_range=25,\n",
        "\t# zoom_range=0.1,\n",
        "\t# width_shift_range=0.1,\n",
        "\t# height_shift_range=0.1,\n",
        "\t# shear_range=0.2,\n",
        "\t# horizontal_flip=True,\n",
        "  # vertical_flip=True,\n",
        "\t# fill_mode=\"nearest\"\n",
        "  )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWJ8ZBoSf8hg"
      },
      "source": [
        "# initialize the validation/testing data augmentation object (which\n",
        "# we'll be adding mean subtraction to)\n",
        "valAug = ImageDataGenerator()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lIkzyUDgAfo"
      },
      "source": [
        "# define the ImageNet mean subtraction (in RGB order) and set the\n",
        "# the mean subtraction value for each of the data augmentation\n",
        "# objects\n",
        "# mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "# trainAug.mean = mean\n",
        "# valAug.mean = mean"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph4f5GXagD-7",
        "outputId": "f79f875a-e745-427b-9c38-2d270ffca983"
      },
      "source": [
        "trainGen = trainAug.flow_from_directory(\n",
        "\tconfig.TRAIN_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(200, 200),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=True,\n",
        "\tbatch_size=config.BS)\n",
        "# initialize the validation generator\n",
        "valGen = valAug.flow_from_directory(\n",
        "\tconfig.VAL_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(200, 200),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=config.BS)\n",
        "# initialize the testing generator\n",
        "testGen = valAug.flow_from_directory(\n",
        "\tconfig.TEST_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(200, 200),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=config.BS)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3309 images belonging to 6 classes.\n",
            "Found 31 images belonging to 6 classes.\n",
            "Found 1022 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4po5oj4TggC_",
        "outputId": "f1e80b43-4366-42b0-eddd-9baeacf3c255"
      },
      "source": [
        "print(\"[INFO] preparing model...\")\n",
        "baseModel = VGG19(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(200, 200, 3)))\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D()(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(len(config.CLASSES), activation=\"softmax\")(headModel)\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n",
        "# compile the model\n",
        "opt = Adam(lr=config.INIT_LR, decay=config.INIT_LR / config.NUM_EPOCHS)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "# train the model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] preparing model...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7cBdl5Of3aG",
        "outputId": "ba08c56d-c441-4647-a266-127ecec5f860"
      },
      "source": [
        "\n",
        "# load the ResNet-50 network, ensuring the head FC layer sets are left\n",
        "# off\n",
        "\n",
        "print(\"[INFO] training model...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=totalTrain // config.BS,\n",
        "\tvalidation_data=valGen,\n",
        "\tvalidation_steps=totalVal // config.BS,\n",
        "\tepochs=config.NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "413/413 [==============================] - 860s 2s/step - loss: 1.4515 - accuracy: 0.4986 - val_loss: 1.7529 - val_accuracy: 0.5833\n",
            "Epoch 2/200\n",
            "413/413 [==============================] - 27s 66ms/step - loss: 0.6268 - accuracy: 0.7873 - val_loss: 1.6110 - val_accuracy: 0.6250\n",
            "Epoch 3/200\n",
            "413/413 [==============================] - 28s 67ms/step - loss: 0.3174 - accuracy: 0.8906 - val_loss: 1.8240 - val_accuracy: 0.5833\n",
            "Epoch 4/200\n",
            "413/413 [==============================] - 28s 67ms/step - loss: 0.1583 - accuracy: 0.9540 - val_loss: 2.5482 - val_accuracy: 0.6250\n",
            "Epoch 5/200\n",
            "413/413 [==============================] - 28s 68ms/step - loss: 0.0873 - accuracy: 0.9743 - val_loss: 2.8163 - val_accuracy: 0.5833\n",
            "Epoch 6/200\n",
            "413/413 [==============================] - 28s 69ms/step - loss: 0.0707 - accuracy: 0.9803 - val_loss: 3.5015 - val_accuracy: 0.6250\n",
            "Epoch 7/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0453 - accuracy: 0.9861 - val_loss: 3.4904 - val_accuracy: 0.5833\n",
            "Epoch 8/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0406 - accuracy: 0.9879 - val_loss: 3.5814 - val_accuracy: 0.5833\n",
            "Epoch 9/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0452 - accuracy: 0.9855 - val_loss: 3.9826 - val_accuracy: 0.5833\n",
            "Epoch 10/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0533 - accuracy: 0.9821 - val_loss: 3.5579 - val_accuracy: 0.6250\n",
            "Epoch 11/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0416 - accuracy: 0.9867 - val_loss: 3.3997 - val_accuracy: 0.5833\n",
            "Epoch 12/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0353 - accuracy: 0.9888 - val_loss: 3.7910 - val_accuracy: 0.5417\n",
            "Epoch 13/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0535 - accuracy: 0.9803 - val_loss: 3.7590 - val_accuracy: 0.7083\n",
            "Epoch 14/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0369 - accuracy: 0.9833 - val_loss: 3.4532 - val_accuracy: 0.6250\n",
            "Epoch 15/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0488 - accuracy: 0.9818 - val_loss: 3.2219 - val_accuracy: 0.5833\n",
            "Epoch 16/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0362 - accuracy: 0.9891 - val_loss: 3.5727 - val_accuracy: 0.6667\n",
            "Epoch 17/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0448 - accuracy: 0.9867 - val_loss: 3.3402 - val_accuracy: 0.6667\n",
            "Epoch 18/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0277 - accuracy: 0.9885 - val_loss: 3.5235 - val_accuracy: 0.6250\n",
            "Epoch 19/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0159 - accuracy: 0.9912 - val_loss: 3.5037 - val_accuracy: 0.6250\n",
            "Epoch 20/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0126 - accuracy: 0.9924 - val_loss: 4.2171 - val_accuracy: 0.6667\n",
            "Epoch 21/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0132 - accuracy: 0.9921 - val_loss: 3.8232 - val_accuracy: 0.6667\n",
            "Epoch 22/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0109 - accuracy: 0.9930 - val_loss: 4.0766 - val_accuracy: 0.6667\n",
            "Epoch 23/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0117 - accuracy: 0.9927 - val_loss: 3.7429 - val_accuracy: 0.5417\n",
            "Epoch 24/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0393 - accuracy: 0.9861 - val_loss: 3.3223 - val_accuracy: 0.6250\n",
            "Epoch 25/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0555 - accuracy: 0.9824 - val_loss: 3.0741 - val_accuracy: 0.6250\n",
            "Epoch 26/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0345 - accuracy: 0.9873 - val_loss: 3.4371 - val_accuracy: 0.7500\n",
            "Epoch 27/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0157 - accuracy: 0.9915 - val_loss: 3.2441 - val_accuracy: 0.7083\n",
            "Epoch 28/200\n",
            "413/413 [==============================] - 29s 69ms/step - loss: 0.0111 - accuracy: 0.9930 - val_loss: 3.1153 - val_accuracy: 0.7500\n",
            "Epoch 29/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0104 - accuracy: 0.9933 - val_loss: 3.0245 - val_accuracy: 0.7500\n",
            "Epoch 30/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0095 - accuracy: 0.9939 - val_loss: 3.4481 - val_accuracy: 0.7500\n",
            "Epoch 31/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0108 - accuracy: 0.9930 - val_loss: 3.4454 - val_accuracy: 0.7083\n",
            "Epoch 32/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0101 - accuracy: 0.9933 - val_loss: 3.2652 - val_accuracy: 0.7500\n",
            "Epoch 33/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0120 - accuracy: 0.9933 - val_loss: 2.9734 - val_accuracy: 0.7083\n",
            "Epoch 34/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0862 - accuracy: 0.9782 - val_loss: 3.7162 - val_accuracy: 0.6250\n",
            "Epoch 35/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0332 - accuracy: 0.9876 - val_loss: 4.2671 - val_accuracy: 0.6667\n",
            "Epoch 36/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0247 - accuracy: 0.9897 - val_loss: 5.5615 - val_accuracy: 0.5833\n",
            "Epoch 37/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 4.0094 - val_accuracy: 0.6250\n",
            "Epoch 38/200\n",
            "413/413 [==============================] - 30s 71ms/step - loss: 0.0089 - accuracy: 0.9936 - val_loss: 4.5774 - val_accuracy: 0.5833\n",
            "Epoch 39/200\n",
            "413/413 [==============================] - 30s 72ms/step - loss: 0.0095 - accuracy: 0.9927 - val_loss: 4.8000 - val_accuracy: 0.5833\n",
            "Epoch 40/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0083 - accuracy: 0.9949 - val_loss: 5.0991 - val_accuracy: 0.5833\n",
            "Epoch 41/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0094 - accuracy: 0.9930 - val_loss: 5.1757 - val_accuracy: 0.5833\n",
            "Epoch 42/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0113 - accuracy: 0.9912 - val_loss: 5.0274 - val_accuracy: 0.5833\n",
            "Epoch 43/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0089 - accuracy: 0.9939 - val_loss: 5.1514 - val_accuracy: 0.5833\n",
            "Epoch 44/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0186 - accuracy: 0.9915 - val_loss: 4.8093 - val_accuracy: 0.5417\n",
            "Epoch 45/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0368 - accuracy: 0.9855 - val_loss: 4.2033 - val_accuracy: 0.7500\n",
            "Epoch 46/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0302 - accuracy: 0.9885 - val_loss: 4.6813 - val_accuracy: 0.5833\n",
            "Epoch 47/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0261 - accuracy: 0.9882 - val_loss: 4.7641 - val_accuracy: 0.7083\n",
            "Epoch 48/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0100 - accuracy: 0.9924 - val_loss: 4.8248 - val_accuracy: 0.6667\n",
            "Epoch 49/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0082 - accuracy: 0.9945 - val_loss: 4.8595 - val_accuracy: 0.6667\n",
            "Epoch 50/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0083 - accuracy: 0.9936 - val_loss: 4.8348 - val_accuracy: 0.6667\n",
            "Epoch 51/200\n",
            "413/413 [==============================] - 30s 72ms/step - loss: 0.0090 - accuracy: 0.9930 - val_loss: 5.0328 - val_accuracy: 0.6667\n",
            "Epoch 52/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0103 - accuracy: 0.9921 - val_loss: 4.9990 - val_accuracy: 0.6667\n",
            "Epoch 53/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0083 - accuracy: 0.9942 - val_loss: 5.0515 - val_accuracy: 0.6667\n",
            "Epoch 54/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0084 - accuracy: 0.9921 - val_loss: 5.2003 - val_accuracy: 0.6667\n",
            "Epoch 55/200\n",
            "413/413 [==============================] - 30s 72ms/step - loss: 0.0290 - accuracy: 0.9873 - val_loss: 4.0028 - val_accuracy: 0.7083\n",
            "Epoch 56/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0430 - accuracy: 0.9867 - val_loss: 5.2223 - val_accuracy: 0.6250\n",
            "Epoch 57/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0220 - accuracy: 0.9888 - val_loss: 4.5134 - val_accuracy: 0.6667\n",
            "Epoch 58/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0207 - accuracy: 0.9897 - val_loss: 4.6157 - val_accuracy: 0.7083\n",
            "Epoch 59/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0096 - accuracy: 0.9942 - val_loss: 4.5903 - val_accuracy: 0.7083\n",
            "Epoch 60/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0089 - accuracy: 0.9921 - val_loss: 4.4101 - val_accuracy: 0.6667\n",
            "Epoch 61/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0083 - accuracy: 0.9939 - val_loss: 4.7267 - val_accuracy: 0.7083\n",
            "Epoch 62/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0084 - accuracy: 0.9933 - val_loss: 4.8710 - val_accuracy: 0.7083\n",
            "Epoch 63/200\n",
            "413/413 [==============================] - 30s 72ms/step - loss: 0.0085 - accuracy: 0.9924 - val_loss: 5.1165 - val_accuracy: 0.7083\n",
            "Epoch 64/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0079 - accuracy: 0.9952 - val_loss: 5.1981 - val_accuracy: 0.7083\n",
            "Epoch 65/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0076 - accuracy: 0.9949 - val_loss: 5.2917 - val_accuracy: 0.7083\n",
            "Epoch 66/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0084 - accuracy: 0.9930 - val_loss: 5.9603 - val_accuracy: 0.7083\n",
            "Epoch 67/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0146 - accuracy: 0.9936 - val_loss: 4.8787 - val_accuracy: 0.7083\n",
            "Epoch 68/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0530 - accuracy: 0.9839 - val_loss: 5.3553 - val_accuracy: 0.6250\n",
            "Epoch 69/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0129 - accuracy: 0.9930 - val_loss: 5.9606 - val_accuracy: 0.6250\n",
            "Epoch 70/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0093 - accuracy: 0.9952 - val_loss: 6.4966 - val_accuracy: 0.6250\n",
            "Epoch 71/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0100 - accuracy: 0.9945 - val_loss: 5.7938 - val_accuracy: 0.6667\n",
            "Epoch 72/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0231 - accuracy: 0.9900 - val_loss: 5.8389 - val_accuracy: 0.6250\n",
            "Epoch 73/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 5.6113 - val_accuracy: 0.6667\n",
            "Epoch 74/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0099 - accuracy: 0.9936 - val_loss: 5.3319 - val_accuracy: 0.7083\n",
            "Epoch 75/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0083 - accuracy: 0.9942 - val_loss: 5.6000 - val_accuracy: 0.6667\n",
            "Epoch 76/200\n",
            "413/413 [==============================] - 30s 72ms/step - loss: 0.0085 - accuracy: 0.9942 - val_loss: 5.6184 - val_accuracy: 0.7083\n",
            "Epoch 77/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0086 - accuracy: 0.9945 - val_loss: 5.1723 - val_accuracy: 0.7083\n",
            "Epoch 78/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0084 - accuracy: 0.9945 - val_loss: 5.1533 - val_accuracy: 0.6667\n",
            "Epoch 79/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0079 - accuracy: 0.9936 - val_loss: 5.2612 - val_accuracy: 0.6667\n",
            "Epoch 80/200\n",
            "413/413 [==============================] - 30s 71ms/step - loss: 0.0099 - accuracy: 0.9949 - val_loss: 4.5426 - val_accuracy: 0.7083\n",
            "Epoch 81/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0083 - accuracy: 0.9936 - val_loss: 5.1949 - val_accuracy: 0.7500\n",
            "Epoch 82/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0092 - accuracy: 0.9930 - val_loss: 5.3036 - val_accuracy: 0.6667\n",
            "Epoch 83/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0082 - accuracy: 0.9933 - val_loss: 5.3844 - val_accuracy: 0.7083\n",
            "Epoch 84/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0080 - accuracy: 0.9927 - val_loss: 5.3058 - val_accuracy: 0.7083\n",
            "Epoch 85/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0079 - accuracy: 0.9936 - val_loss: 5.6472 - val_accuracy: 0.7083\n",
            "Epoch 86/200\n",
            "413/413 [==============================] - 30s 72ms/step - loss: 0.0083 - accuracy: 0.9933 - val_loss: 5.5823 - val_accuracy: 0.7083\n",
            "Epoch 87/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0078 - accuracy: 0.9949 - val_loss: 5.5704 - val_accuracy: 0.7083\n",
            "Epoch 88/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0077 - accuracy: 0.9949 - val_loss: 5.5455 - val_accuracy: 0.7083\n",
            "Epoch 89/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0094 - accuracy: 0.9949 - val_loss: 5.9909 - val_accuracy: 0.6667\n",
            "Epoch 90/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0734 - accuracy: 0.9833 - val_loss: 5.2375 - val_accuracy: 0.6250\n",
            "Epoch 91/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0327 - accuracy: 0.9900 - val_loss: 5.5540 - val_accuracy: 0.6250\n",
            "Epoch 92/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0098 - accuracy: 0.9930 - val_loss: 5.5182 - val_accuracy: 0.5833\n",
            "Epoch 93/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0084 - accuracy: 0.9939 - val_loss: 5.5719 - val_accuracy: 0.5833\n",
            "Epoch 94/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0078 - accuracy: 0.9952 - val_loss: 5.2723 - val_accuracy: 0.5833\n",
            "Epoch 95/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0087 - accuracy: 0.9952 - val_loss: 5.4804 - val_accuracy: 0.6250\n",
            "Epoch 96/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0082 - accuracy: 0.9933 - val_loss: 5.6037 - val_accuracy: 0.6250\n",
            "Epoch 97/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0085 - accuracy: 0.9933 - val_loss: 5.3283 - val_accuracy: 0.5833\n",
            "Epoch 98/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0114 - accuracy: 0.9942 - val_loss: 5.4643 - val_accuracy: 0.5833\n",
            "Epoch 99/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0083 - accuracy: 0.9936 - val_loss: 5.6438 - val_accuracy: 0.5833\n",
            "Epoch 100/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0085 - accuracy: 0.9933 - val_loss: 5.7077 - val_accuracy: 0.5833\n",
            "Epoch 101/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0080 - accuracy: 0.9936 - val_loss: 5.7878 - val_accuracy: 0.6250\n",
            "Epoch 102/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0084 - accuracy: 0.9921 - val_loss: 5.7028 - val_accuracy: 0.5833\n",
            "Epoch 103/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0080 - accuracy: 0.9939 - val_loss: 5.8266 - val_accuracy: 0.6250\n",
            "Epoch 104/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0079 - accuracy: 0.9933 - val_loss: 5.8950 - val_accuracy: 0.6250\n",
            "Epoch 105/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0074 - accuracy: 0.9955 - val_loss: 6.0621 - val_accuracy: 0.6250\n",
            "Epoch 106/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0081 - accuracy: 0.9930 - val_loss: 6.0492 - val_accuracy: 0.6250\n",
            "Epoch 107/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0692 - accuracy: 0.9842 - val_loss: 3.5920 - val_accuracy: 0.6667\n",
            "Epoch 108/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0242 - accuracy: 0.9888 - val_loss: 4.7750 - val_accuracy: 0.7083\n",
            "Epoch 109/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0238 - accuracy: 0.9909 - val_loss: 4.2150 - val_accuracy: 0.7083\n",
            "Epoch 110/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0094 - accuracy: 0.9939 - val_loss: 4.9651 - val_accuracy: 0.7083\n",
            "Epoch 111/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0087 - accuracy: 0.9927 - val_loss: 5.4256 - val_accuracy: 0.7083\n",
            "Epoch 112/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0083 - accuracy: 0.9927 - val_loss: 5.2481 - val_accuracy: 0.7500\n",
            "Epoch 113/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0077 - accuracy: 0.9945 - val_loss: 5.2919 - val_accuracy: 0.7083\n",
            "Epoch 114/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0079 - accuracy: 0.9936 - val_loss: 5.3974 - val_accuracy: 0.7083\n",
            "Epoch 115/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0075 - accuracy: 0.9949 - val_loss: 5.6619 - val_accuracy: 0.7083\n",
            "Epoch 116/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0085 - accuracy: 0.9936 - val_loss: 5.1455 - val_accuracy: 0.7500\n",
            "Epoch 117/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0077 - accuracy: 0.9955 - val_loss: 5.3032 - val_accuracy: 0.7500\n",
            "Epoch 118/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0072 - accuracy: 0.9955 - val_loss: 5.5701 - val_accuracy: 0.7500\n",
            "Epoch 119/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0087 - accuracy: 0.9952 - val_loss: 5.5715 - val_accuracy: 0.7500\n",
            "Epoch 120/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0097 - accuracy: 0.9933 - val_loss: 5.7312 - val_accuracy: 0.7500\n",
            "Epoch 121/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 4.3612 - val_accuracy: 0.7500\n",
            "Epoch 122/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0204 - accuracy: 0.9909 - val_loss: 6.1590 - val_accuracy: 0.6667\n",
            "Epoch 123/200\n",
            "413/413 [==============================] - 30s 72ms/step - loss: 0.0108 - accuracy: 0.9945 - val_loss: 7.0136 - val_accuracy: 0.7083\n",
            "Epoch 124/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0174 - accuracy: 0.9912 - val_loss: 7.3707 - val_accuracy: 0.6667\n",
            "Epoch 125/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0345 - accuracy: 0.9870 - val_loss: 7.6158 - val_accuracy: 0.7083\n",
            "Epoch 126/200\n",
            "413/413 [==============================] - 30s 72ms/step - loss: 0.0125 - accuracy: 0.9936 - val_loss: 5.6477 - val_accuracy: 0.7083\n",
            "Epoch 127/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0145 - accuracy: 0.9927 - val_loss: 6.0817 - val_accuracy: 0.7083\n",
            "Epoch 128/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0080 - accuracy: 0.9952 - val_loss: 6.3878 - val_accuracy: 0.7083\n",
            "Epoch 129/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0082 - accuracy: 0.9939 - val_loss: 6.6942 - val_accuracy: 0.7083\n",
            "Epoch 130/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0078 - accuracy: 0.9942 - val_loss: 6.7033 - val_accuracy: 0.7083\n",
            "Epoch 131/200\n",
            "413/413 [==============================] - 29s 70ms/step - loss: 0.0079 - accuracy: 0.9936 - val_loss: 6.7976 - val_accuracy: 0.7083\n",
            "Epoch 132/200\n",
            "413/413 [==============================] - 30s 71ms/step - loss: 0.0077 - accuracy: 0.9949 - val_loss: 6.8100 - val_accuracy: 0.7083\n",
            "Epoch 133/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0078 - accuracy: 0.9945 - val_loss: 6.7491 - val_accuracy: 0.7083\n",
            "Epoch 134/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0083 - accuracy: 0.9942 - val_loss: 6.9874 - val_accuracy: 0.7500\n",
            "Epoch 135/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0084 - accuracy: 0.9939 - val_loss: 6.4504 - val_accuracy: 0.7500\n",
            "Epoch 136/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0090 - accuracy: 0.9930 - val_loss: 5.4836 - val_accuracy: 0.7083\n",
            "Epoch 137/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0074 - accuracy: 0.9952 - val_loss: 6.2397 - val_accuracy: 0.7500\n",
            "Epoch 138/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0081 - accuracy: 0.9949 - val_loss: 7.4632 - val_accuracy: 0.7083\n",
            "Epoch 139/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0088 - accuracy: 0.9952 - val_loss: 6.1724 - val_accuracy: 0.7083\n",
            "Epoch 140/200\n",
            "413/413 [==============================] - 29s 71ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 6.9235 - val_accuracy: 0.7083\n",
            "Epoch 141/200\n",
            "391/413 [===========================>..] - ETA: 1s - loss: 0.0544 - accuracy: 0.9866"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj41CXepgq1Q"
      },
      "source": [
        "print(\"[INFO] evaluating network...\")\n",
        "testGen.reset()\n",
        "predIdxs = model.predict_generator(testGen,\n",
        "\tsteps=(totalTest // config.BS) + 1)\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testGen.classes, predIdxs,\n",
        "\ttarget_names=testGen.class_indices.keys()))\n",
        "# serialize the model to disk\n",
        "print(\"[INFO] saving model...\")\n",
        "model.save(config.MODEL_PATH, save_format=\"h5\")\n",
        "N = config.NUM_EPOCHS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUGR_HTRgNhC"
      },
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"VGG19_ADAM_plot.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEcaVZFjhvEF"
      },
      "source": [
        "H.history"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}